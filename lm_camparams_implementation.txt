https://engineering.purdue.edu/kak/computervision/ECE661/Kihyun%20Hong_HW5.pdf pg 55-

/
// function : RefineCameraParameters
// usage : RefineCameraParameters(cp, imagePt);
//-----------------------------------------------------------------
// this function refines camera parameters using LM algorithm
// in this function, error(geometric distance) is calcualted using
// whole image set, however, camera parameters are updated image by image
// because Jacobian calculation for whole image set is somewhat not preferable
//
void RefineCameraParameters(CameraParam *cp, PairPointSet *imagePt) {
int numOfImages =  imagePt->imageLen;
int numOfData = 2 * imagePt->pointLen * numOfImages;
int numOfParams = 7 + numOfImages * 6;
// Jx & Jy size : 7 + numOfImage * 6
int numOfIteration = NUM_OF_ITERATION;
int numOfPoints = imagePt->pointLen;
int iterationNum;
double e, eNew;
double lambda = LAMBDA;
bool update = true;
int i, m, k;
double X, Y;
double theta, a;
double Jx[numOfParams], Jy[numOfParams];
CvScalar tr;
double au;
double av;
double u0;
double v0;
double sk;
double k1;
double k2;
double wx[numOfImages], wy[numOfImages], wz[numOfImages];
double tx[numOfImages], ty[numOfImages], tz[numOfImages];
double wxNew, wyNew, wzNew;
float stepSize = 1; // default stepSize = 1
CvMat *R = cvCreateMat(3, 3, CV_64FC1);
CvMat *J = cvCreateMat(numOfData, numOfParams, CV_64FC1);
CvMat *Hessian = cvCreateMat(numOfParams, numOfParams, CV_64FC1);
CvMat *invHessian = cvCreateMat(numOfParams, numOfParams, CV_64FC1);
CvMat *transJ = cvCreateMat(numOfParams, numOfData, CV_64FC1);
CvMat *Jerr = cvCreateMat(numOfParams, 1, CV_64FC1);
CvMat *dp = cvCreateMat(numOfParams, 1, CV_64FC1);
CvMat *d = cvCreateMat(numOfData, 1, CV_64FC1);
CvMat *dLM = cvCreateMat(numOfData, 1, CV_64FC1);
e = CalculateError(cp, imagePt, d);
printf("initial error = %f\n", e);
for(iterationNum = 0; iterationNum < numOfIteration; iterationNum++){
if(update == true){
for(k = 0; k < numOfImages; k++){
//Rodigrues representation
for(m = 0; m < 3; m++){
cvmSet(R, m, 0, cp->r1[m][k]);
cvmSet(R, m, 1, cp->r2[m][k]);
cvmSet(R, m, 2, cp->r3[m][k]);
}
tr = cvTrace(R); // trace(R) -> tr.val[0]
theta = acos((tr.val[0] - 1) / 2.0);
a = (theta / (2 * sin(theta)));
wx[k] = a * (cvmGet(R, 2, 1) - cvmGet(R, 1, 2));
wy[k] = a * (cvmGet(R, 0, 2) - cvmGet(R, 2, 0));
wz[k] = a * (cvmGet(R, 1, 0) - cvmGet(R, 0, 1));
tx[k] = cp->t[0][k];
ty[k] = cp->t[1][k];
tz[k] = cp->t[2][k];
au = cp->alphaX;
av = cp->alphaY;
u0 = cp->x0;
v0 = cp->y0;
sk = cp->skew;
k1 = cp->k1;
k2 = cp->k2;
for(i = 0; i < numOfPoints; i++){
//Evaluate the Jacobian at the current parameter values
// and the values of geometric distance
X = imagePt-> ptmJ[i][k];
Y = imagePt-> ptmI[i][k];
CalculateJocobian(Jx, Jy, k, numOfParams,
X, Y, au, av, u0, v0, sk,
wx[k], wy[k], wz[k], tx[k], ty[k], tz[k],
k1, k2);
for(m = 0; m < numOfParams; m++){
cvmSet(J, i * 2 + k * numOfPoints * 2, m, Jx[m]);
cvmSet(J, i * 2 + 1 + k * numOfPoints * 2, m, Jy[m]);
}
}
}
// compute the approximated Hessian matrix
cvMulTransposed (J, Hessian, 1); // Hessian =J'J
}
// update camera parameters (cp)
// apply the damping factor to the Hessian matrix
for(m = 0; m < numOfParams; m++){
double tmp = cvmGet(Hessian, m, m);
cvmSet(Hessian, m, m, tmp + lambda);
}
// compute the updated parameters
// dp = inv(Hessian)*(J'*d(:));
cvTranspose(J, transJ);
cvMatMul(transJ, d, Jerr);
cvInvert(Hessian, invHessian, CV_SVD_SYM);
cvMatMul(invHessian, Jerr, dp);
cp->alphaX = au - cvmGet(dp, 0, 0) * stepSize;
cp->alphaY = av - cvmGet(dp, 1, 0) * stepSize;
cp->x0 = u0 - cvmGet(dp, 2, 0) * stepSize;
cp->y0 = v0 - cvmGet(dp, 3, 0) * stepSize;
cp->skew = sk - cvmGet(dp, 4, 0) * stepSize;
cp->k1 = k1 - cvmGet(dp, numOfParams - 2, 0) * stepSize;
cp->k2 = k2 - cvmGet(dp, numOfParams - 1, 0) * stepSize;
for(k = 0; k < numOfImages; k++){
wxNew = wx[k] - cvmGet(dp, 5 + k * 6, 0) * stepSize;
wyNew = wy[k] - cvmGet(dp, 6 + k * 6, 0) * stepSize;
wzNew = wz[k] - cvmGet(dp, 7 + k * 6, 0) * stepSize;
cp->t[0][k] = tx[k] - cvmGet(dp, 8 + k * 6, 0) * stepSize;
cp->t[1][k] = ty[k] - cvmGet(dp, 9 + k * 6, 0) * stepSize;
cp->t[2][k] = tz[k] - cvmGet(dp, 10 + k * 6, 0) * stepSize;
// convert the 3-vector [wx wy wz] of the Rodigrues representation
// into the 3x3 rotation matrix
Rodrigues2R(wxNew, wyNew, wzNew, R);
for(m = 0; m < 3; m++){
cp->r1[m][k] = cvmGet(R, m, 0);
cp->r2[m][k] = cvmGet(R, m, 1);
cp->r3[m][k] = cvmGet(R, m, 2);
}
}
//Evaluate the total geometric distance at the updated parameters
eNew = CalculateError(cp, imagePt, dLM);
// if the total geometric distance of the updated parameters is
// less than the previous one then makes the updated parameters
// to be the current parameters and decreases
// the value of the damping factor
if(eNew < e){
lambda = lambda / 10;
e = CalculateError(cp, imagePt, d);
update = true;
}else{ // reverse updated data
update = false;
lambda = lambda * 20;
cp->alphaX = au;
cp->alphaY = av;
cp->x0 = u0;
cp->y0 = v0;
cp->skew = sk;
cp->k1 = k1;
cp->k2 = k2;
for(k = 0; k < numOfImages; k++){
cp->t[0][k] = tx[k];
cp->t[1][k] = ty[k];
cp->t[2][k] = tz[k];
Rodrigues2R(wx[k], wy[k], wz[k], R);
for(m = 0; m < 3; m++){
cp->r1[m][k] = cvmGet(R, m, 0);
cp->r2[m][k] = cvmGet(R, m, 1);
cp->r3[m][k] = cvmGet(R, m, 2);
}
}
}
}
printf("refined error = %f\n", e);
cvReleaseMat(&R); cvReleaseMat(&J); cvReleaseMat(&Hessian);
cvReleaseMat(&dp); cvReleaseMat(&d); cvReleaseMat(&dLM);
cvReleaseMat(&invHessian); cvReleaseMat(&transJ); cvReleaseMat(&Jerr);
}
double CalculateError(CameraParam *cp, PairPointSet *imagePt, CvMat *d) {
float au = cp->alphaX;
float av = cp->alphaY;
float u0 = cp->x0;
float v0 = cp->y0;
float sk = cp->skew;
float k1 = cp->k1;
float k2 = cp->k2;
int k, i;
int numOfImages = imagePt->imageLen;
int numOfPoints = imagePt->pointLen;
double x1, x2, x3, u, v, X, Y, ui, vi;
double tpU , tpV , r;
CvMat *A = cvCreateMat(3, 3, CV_64FC1);
CvMat *K = cvCreateMat(3, 3, CV_64FC1);
CvMat *H = cvCreateMat(3, 3, CV_64FC1);
for(k = 0; k < numOfImages; k++){
//H = KA, where A = [r1 r2 t];
for(i = 0; i < 3; i++){
cvmSet(A, i, 0, cp->r1[i][k]);
cvmSet(A, i, 1, cp->r2[i][k]);
cvmSet(A, i, 2, cp->t[i][k]);
}
float kArr[9] = {au, sk, u0,
0, av, v0,
0,  0,  1};
Array2CvMat(kArr, K, 3, 3);
cvMatMul(K, A, H);
float h[9];
CvMat2Array(H, h, 3, 3);
// get ideal points
for(i = 0; i < numOfPoints; i++){
X = imagePt->ptmJ[i][k];
Y = imagePt->ptmI[i][k];
x1 = h[0] * X + h[1] * Y + h[2];
x2 = h[3] * X + h[4] * Y + h[5];
x3 = h[6] * X + h[7] * Y + h[8];
// get ideal points
ui = x1 / x3;
vi = x2 / x3;
// radial distortion
tpU = (ui - u0);
tpV = (vi - v0);
r = pow(tpU / au , 2) + pow(tpV / av, 2);
u = ui + tpU * (k1 * r + k2 * pow(r, 2));
v = vi + tpV * (k1 * r + k2 * pow(r, 2));
cvmSet(d, i*2 + k*numOfPoints*2, 0,
imagePt->ptiJ[i][k] - u);
cvmSet(d, i*2 + 1 + k*numOfPoints*2, 0,
imagePt->ptiI[i][k] - v);
}
}
int numOfData = numOfPoints * numOfImages;
double e = cvDotProduct(d, d) / numOfData;
cvReleaseMat(&A); cvReleaseMat(&H); cvReleaseMat(&K);
return(e);
}
void Rodrigues2R(float wx, float wy, float wz, CvMat *R){
CvMat* W = cvCreateMat(3, 3, CV_64FC1);
CvMat* Ws = cvCreateMat(3, 3, CV_64FC1);
CvMat* W2 = cvCreateMat(3, 3, CV_64FC1);
CvMat* W2s = cvCreateMat(3, 3, CV_64FC1);
CvMat* Rtmp = cvCreateMat(3, 3, CV_64FC1);
CvMat* Eye = cvCreateMat(3, 3, CV_64FC1);
// convert the 3-vector [wx wy wz] of
// the Rodigrues representation
// into the 3x3 rotation matrix
float norm2 = pow(wx, 2) + pow(wy, 2) + pow(wz, 2);
float norm = sqrt(norm2);
float omega[9] = {0, -wz,  wy,
wz,   0, -wx,
-wy,  wx,   0};
Array2CvMat(omega, W, 3, 3);
float a1 = (sin(norm) / norm);
float a2 = ((1 - cos(norm)) / norm2);
cvmScale(W, Ws, a1);
cvMatMul(W, W, W2);
cvmScale(W2, W2s, a2);
float I[9] = {1, 0, 0,
0, 1, 0,
0, 0, 1};
Array2CvMat(I, Eye, 3, 3);
cvAdd(Eye, Ws, Rtmp); //R = Eye + Ws + W2s;
cvAdd(Rtmp, W2s, R);
cvReleaseMat(&W); cvReleaseMat(&W2);
cvReleaseMat(&Ws); cvReleaseMat(&W2s);
cvReleaseMat(&Rtmp); cvReleaseMat(&Eye);
}

